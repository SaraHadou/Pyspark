{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 233,
      "id": "RJLhV-4rYfDi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJLhV-4rYfDi",
        "outputId": "883adfad-2849-45b2-87fe-57efc2618b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n",
            "Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9da32d6",
      "metadata": {
        "id": "c9da32d6"
      },
      "source": [
        "# NLP Using PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8326ba88",
      "metadata": {
        "id": "8326ba88"
      },
      "source": [
        "## Objective:\n",
        "- The objective from this project is to create a <b>Spam filter using NaiveBayes classifier</b>.\n",
        "- It is required to obtain <b>f1_scored > 0.9</b>.\n",
        "- We'll use a dataset from UCI Repository. SMS Spam Detection: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
        "- Data is also provided for you in the assignment (you do not have to download it)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6971f788",
      "metadata": {
        "id": "6971f788"
      },
      "source": [
        "## To perform this task follow the following guiding steps:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31bc851",
      "metadata": {
        "id": "e31bc851"
      },
      "source": [
        "### Create a spark session and import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "id": "dcf86e46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "dcf86e46",
        "outputId": "f19aa8bc-a9fe-445d-d3a1-42be95f4a563"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f8d56b04e74a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f2742d7a7d0>"
            ]
          },
          "execution_count": 234,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c7df9e",
      "metadata": {
        "id": "90c7df9e"
      },
      "source": [
        "### Read the readme file to learn more about the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d00718f",
      "metadata": {
        "id": "2d00718f"
      },
      "source": [
        "### Read the data into a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "id": "29914cf1",
      "metadata": {
        "id": "29914cf1"
      },
      "outputs": [],
      "source": [
        "totalDF = spark.read.format(\"csv\")\\\n",
        "                .option(\"header\", \"false\")\\\n",
        "                .option(\"delimiter\", \"\\t\")\\\n",
        "                .option(\"inferSchema\", \"true\").load('/content/SMSSpamCollection')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "id": "aCvWjm3waNFQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCvWjm3waNFQ",
        "outputId": "e3bd4f27-cd39-4f14-b291-79fc4f5bfa28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+--------------------+\n",
            "| _c0|                 _c1|\n",
            "+----+--------------------+\n",
            "| ham|Go until jurong p...|\n",
            "| ham|Ok lar... Joking ...|\n",
            "|spam|Free entry in 2 a...|\n",
            "| ham|U dun say so earl...|\n",
            "| ham|Nah I don't think...|\n",
            "+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "totalDF.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182cd7f6",
      "metadata": {
        "id": "182cd7f6"
      },
      "source": [
        "### Print the schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "id": "Z8IDXZBvaxKX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8IDXZBvaxKX",
        "outputId": "0e4da65e-014a-422d-9425-f030cca9d935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- _c1: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "totalDF.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b90cce7",
      "metadata": {
        "id": "2b90cce7"
      },
      "source": [
        "### Rename the first column to 'class' and second column to 'text'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "id": "uVX9bM_8a11d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVX9bM_8a11d",
        "outputId": "54acc8c0-69fe-40a3-f4f5-e5b2d9abd63f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "totalDF = totalDF.withColumnRenamed(\"_c0\", \"class\")\n",
        "totalDF = totalDF.withColumnRenamed(\"_c1\", \"text\")\n",
        "\n",
        "totalDF.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e798d0",
      "metadata": {
        "id": "a3e798d0"
      },
      "source": [
        "### Show the first 10 rows from the dataframe\n",
        "- Show once with truncate=True and once with truncate=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "id": "0qdmtDjQb8LA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qdmtDjQb8LA",
        "outputId": "75f819ec-92f7-4c28-c244-b765292c2df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|class|                text|\n",
            "+-----+--------------------+\n",
            "|  ham|Go until jurong p...|\n",
            "|  ham|Ok lar... Joking ...|\n",
            "| spam|Free entry in 2 a...|\n",
            "|  ham|U dun say so earl...|\n",
            "|  ham|Nah I don't think...|\n",
            "| spam|FreeMsg Hey there...|\n",
            "|  ham|Even my brother i...|\n",
            "|  ham|As per your reque...|\n",
            "| spam|WINNER!! As a val...|\n",
            "| spam|Had your mobile 1...|\n",
            "+-----+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "totalDF.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "id": "z5P_3lurcG-d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5P_3lurcG-d",
        "outputId": "b5ffc29f-b966-4793-81c7-dd8b8e82e911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|class|text                                                                                                                                                            |\n",
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|ham  |Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...                                                 |\n",
            "|ham  |Ok lar... Joking wif u oni...                                                                                                                                   |\n",
            "|spam |Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's     |\n",
            "|ham  |U dun say so early hor... U c already then say...                                                                                                               |\n",
            "|ham  |Nah I don't think he goes to usf, he lives around here though                                                                                                   |\n",
            "|spam |FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv             |\n",
            "|ham  |Even my brother is not like to speak with me. They treat me like aids patent.                                                                                   |\n",
            "|ham  |As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune|\n",
            "|spam |WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.   |\n",
            "|spam |Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030      |\n",
            "+-----+----------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "totalDF.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fe744a9",
      "metadata": {
        "id": "2fe744a9"
      },
      "source": [
        "## Clean and Prepare the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d693167",
      "metadata": {
        "id": "4d693167"
      },
      "source": [
        "### Create a new feature column contains the length of the text column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "id": "5424a0cb",
      "metadata": {
        "id": "5424a0cb"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import length\n",
        "totalDF = totalDF.withColumn('length', length(totalDF.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78ea2de6",
      "metadata": {
        "id": "78ea2de6"
      },
      "source": [
        "### Show the new dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "id": "4gQ9mRiSd8Zm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gQ9mRiSd8Zm",
        "outputId": "eed506dc-b116-40ad-8a74-4d468326f94d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------+\n",
            "|class|                text|length|\n",
            "+-----+--------------------+------+\n",
            "|  ham|Go until jurong p...|   111|\n",
            "|  ham|Ok lar... Joking ...|    29|\n",
            "| spam|Free entry in 2 a...|   155|\n",
            "|  ham|U dun say so earl...|    49|\n",
            "|  ham|Nah I don't think...|    61|\n",
            "| spam|FreeMsg Hey there...|   147|\n",
            "|  ham|Even my brother i...|    77|\n",
            "|  ham|As per your reque...|   160|\n",
            "| spam|WINNER!! As a val...|   157|\n",
            "| spam|Had your mobile 1...|   154|\n",
            "|  ham|I'm gonna be home...|   109|\n",
            "| spam|SIX chances to wi...|   136|\n",
            "| spam|URGENT! You have ...|   155|\n",
            "|  ham|I've been searchi...|   196|\n",
            "|  ham|I HAVE A DATE ON ...|    35|\n",
            "| spam|XXXMobileMovieClu...|   149|\n",
            "|  ham|Oh k...i'm watchi...|    26|\n",
            "|  ham|Eh u remember how...|    81|\n",
            "|  ham|Fine if thats th...|    56|\n",
            "| spam|England v Macedon...|   155|\n",
            "+-----+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "totalDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "692e37a6",
      "metadata": {
        "id": "692e37a6"
      },
      "source": [
        "### Get the average text length for each class (give alias name to the average length column)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "id": "srXJ8Eg7eHKD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srXJ8Eg7eHKD",
        "outputId": "0638efa3-cc41-4ad8-c690-991615670a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------------+\n",
            "|class|      Avg. Length|\n",
            "+-----+-----------------+\n",
            "|  ham|71.45431945307645|\n",
            "| spam|138.6706827309237|\n",
            "+-----+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import avg\n",
        "\n",
        "lengthDF = totalDF.groupBy('class').agg(avg('length').alias(\"Avg. Length\"))\n",
        "lengthDF.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5e101af",
      "metadata": {
        "id": "d5e101af"
      },
      "source": [
        "## Feature Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "838ad9dd",
      "metadata": {
        "id": "838ad9dd"
      },
      "source": [
        "### In this part you transform you raw text in to tf_idf model :\n",
        "- For more information about TF-IDF check the following link: <b>(Not needed for the test)</b>\n",
        "https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "225067d5",
      "metadata": {
        "id": "225067d5"
      },
      "source": [
        "### Perform the following steps to obtain TF-IDF:\n",
        "1. Import the required transformers/estimators for the subsequent steps.\n",
        "2. Create a <b>Tokenizer</b> from the text column.\n",
        "3. Create a <b>StopWordsRemover</b> to remove the <b>stop words</b> from the column obtained from the <b>Tokenizer</b>.\n",
        "4. Create a <b>CountVectorizer</b> after removing the <b>stop words</b>.\n",
        "5. Create the <b>TF-IDF</b> from the <b>CountVectorizer</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "id": "b82756db",
      "metadata": {
        "id": "b82756db"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "count_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')\n",
        "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1527ad65",
      "metadata": {
        "id": "1527ad65"
      },
      "source": [
        "- Convert the <b>class column</b> to index using <b>StringIndexer</b>\n",
        "- Create feature column from the <b>TF-IDF</b> and <b>lenght</b> columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "id": "Nn--POaVkrfs",
      "metadata": {
        "id": "Nn--POaVkrfs"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "ham_spam_to_num = StringIndexer(inputCol='class',outputCol='label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "id": "-XOa_lHjp15w",
      "metadata": {
        "id": "-XOa_lHjp15w"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "clean = VectorAssembler(inputCols=['tf_idf','length'],outputCol='features')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9775d494",
      "metadata": {
        "id": "9775d494"
      },
      "source": [
        "## The Model\n",
        "- Create a <b>NaiveBayes</b> classifier with the default parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "id": "57af0d5d",
      "metadata": {
        "id": "57af0d5d"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "clf = NaiveBayes()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc14de63",
      "metadata": {
        "id": "dc14de63"
      },
      "source": [
        "## Pipeline\n",
        "### Create a pipeline model contains all the steps starting from the Tokenizer to the NaiveBays classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "id": "8ee0d1ca",
      "metadata": {
        "id": "8ee0d1ca"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[ham_spam_to_num, tokenizer, stopremove, count_vec, idf, clean, clf])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d7efbe",
      "metadata": {
        "id": "f5d7efbe"
      },
      "source": [
        "### Split your data to trian and test data with ratios 0.7 and 0.3 respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "id": "hiys8z0Yq7Gq",
      "metadata": {
        "id": "hiys8z0Yq7Gq"
      },
      "outputs": [],
      "source": [
        "trainDF, testDF = totalDF.randomSplit([0.7, 0.3])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bcea576",
      "metadata": {
        "id": "8bcea576"
      },
      "source": [
        "### Fit your Pipeline model to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "3c5d4681",
      "metadata": {
        "id": "3c5d4681"
      },
      "outputs": [],
      "source": [
        "spamPred = pipeline.fit(trainDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228a3eb1",
      "metadata": {
        "id": "228a3eb1"
      },
      "source": [
        "### Perform predictions on tests dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "id": "14f4aab5",
      "metadata": {
        "id": "14f4aab5"
      },
      "outputs": [],
      "source": [
        "predictions = spamPred.transform(testDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "id": "w11xfep-rT9u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w11xfep-rT9u",
        "outputId": "9b97b876-a71d-46b1-e399-f30f5d277242"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|class|                text|length|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|       rawPrediction|         probability|prediction|\n",
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|  ham| &lt;DECIMAL&gt; ...|   132|  0.0|[, &lt;decimal&gt...|[, &lt;decimal&gt...|(10805,[3,92,108,...|(10805,[3,92,108,...|(10806,[3,92,108,...|[-779.06627846623...|[1.0,1.9791742347...|       0.0|\n",
            "|  ham|\"Response\" is one...|   154|  0.0|[\"response\", is, ...|[\"response\", one,...|(10805,[2,7,27,61...|(10805,[2,7,27,61...|(10806,[2,7,27,61...|[-764.02824100286...|[1.0,1.4416368212...|       0.0|\n",
            "|  ham|\"Wen u miss someo...|   143|  0.0|[\"wen, u, miss, s...|[\"wen, u, miss, s...|(10805,[0,78,210,...|(10805,[0,78,210,...|(10806,[0,78,210,...|[-347.12618841821...|[1.0,2.0020928443...|       0.0|\n",
            "|  ham|&lt;#&gt;  am I t...|    45|  0.0|[&lt;#&gt;, , am,...|[&lt;#&gt;, , thi...|(10805,[3,8,64],[...|(10805,[3,8,64],[...|(10806,[3,8,64,10...|[-97.005290835352...|[1.0,3.5993486843...|       0.0|\n",
            "|  ham|&lt;#&gt;  great ...|    85|  0.0|[&lt;#&gt;, , gre...|[&lt;#&gt;, , gre...|(10805,[3,8,37,59...|(10805,[3,8,37,59...|(10806,[3,8,37,59...|[-525.63180710912...|[1.0,5.3698371138...|       0.0|\n",
            "|  ham|&lt;#&gt;  is fas...|   461|  0.0|[&lt;#&gt;, , is,...|[&lt;#&gt;, , fas...|(10805,[0,3,7,8,1...|(10805,[0,3,7,8,1...|(10806,[0,3,7,8,1...|[-1929.3878299266...|[1.0,9.8260394884...|       0.0|\n",
            "|  ham|&lt;#&gt; %of ppl...|   327|  0.0|[&lt;#&gt;, %of, ...|[&lt;#&gt;, %of, ...|(10805,[0,2,3,5,8...|(10805,[0,2,3,5,8...|(10806,[0,2,3,5,8...|[-1664.2924277252...|[1.0,1.3863788150...|       0.0|\n",
            "|  ham|(No promises on w...|    60|  0.0|[(no, promises, o...|[(no, promises, t...|(10805,[118,353,4...|(10805,[118,353,4...|(10806,[118,353,4...|[-273.04249503479...|[1.0,1.9732828962...|       0.0|\n",
            "|  ham|      * Am on my way|    14|  0.0|[*, am, on, my, way]|            [*, way]|(10805,[79,183],[...|(10805,[79,183],[...|(10806,[79,183,10...|[-80.727622833014...|[0.99999999999998...|       0.0|\n",
            "|  ham|* Thought I didn'...|    27|  0.0|[*, thought, i, d...|[*, thought, see,...|(10805,[37,86,169...|(10805,[37,86,169...|(10806,[37,86,169...|[-154.65662851727...|[1.0,4.1759331926...|       0.0|\n",
            "|  ham|* Will have two m...|    67|  0.0|[*, will, have, t...|[*, two, cartons,...|(10805,[0,183,232...|(10805,[0,183,232...|(10806,[0,183,232...|[-203.77766845562...|[0.99999904535435...|       0.0|\n",
            "|  ham|*deep sigh* ... I...|   129|  0.0|[*deep, sigh*, .....|[*deep, sigh*, .....|(10805,[5,18,78,8...|(10805,[5,18,78,8...|(10806,[5,18,78,8...|[-762.73698000583...|[1.0,4.1174246349...|       0.0|\n",
            "|  ham|, ,  and  picking...|   169|  0.0|[,, ,, , and, , p...|[,, ,, , , pickin...|(10805,[0,2,3,7,2...|(10805,[0,2,3,7,2...|(10806,[0,2,3,7,2...|[-1286.6895566995...|[1.0,5.2808526039...|       0.0|\n",
            "|  ham|... Are you in th...|    23|  0.0|[..., are, you, i...|         [..., pub?]|  (10805,[18],[1.0])|(10805,[18],[4.00...|(10806,[18,10805]...|[-39.884760447180...|[0.99999997076488...|       0.0|\n",
            "|  ham|.Please charge my...|    52|  0.0|[.please, charge,...|[.please, charge,...|(10805,[5,39,753,...|(10805,[5,39,753,...|(10806,[5,39,753,...|[-195.96230625376...|[0.99987496575274...|       0.0|\n",
            "|  ham|1) Go to write ms...|   141|  0.0|[1), go, to, writ...|[1), go, write, m...|(10805,[3,4,6,8,1...|(10805,[3,4,6,8,1...|(10806,[3,4,6,8,1...|[-1168.8183270559...|[1.0,6.0444651805...|       0.0|\n",
            "|  ham|   10 min later k...|    17|  0.0|[10, min, later, ...|[10, min, later, ...|(10805,[55,391,78...|(10805,[55,391,78...|(10806,[55,391,78...|[-230.15733620957...|[0.99999999366374...|       0.0|\n",
            "|  ham|2marrow only. Wed...|    42|  0.0|[2marrow, only., ...|[2marrow, only., ...|(10805,[2,3,8,602...|(10805,[2,3,8,602...|(10806,[2,3,8,602...|[-382.72633949212...|[1.0,4.8383109521...|       0.0|\n",
            "|  ham|7 lor... Change 2...|    46|  0.0|[7, lor..., chang...|[7, lor..., chang...|(10805,[0,2,21,10...|(10805,[0,2,21,10...|(10806,[0,2,21,10...|[-330.87441685036...|[1.0,1.5498386557...|       0.0|\n",
            "|  ham|             :-) :-)|     7|  0.0|          [:-), :-)]|          [:-), :-)]| (10805,[351],[2.0])|(10805,[351],[10....|(10806,[351,10805...|[-96.173328726625...|[1.0,4.0324364790...|       0.0|\n",
            "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bce2885f",
      "metadata": {
        "id": "bce2885f"
      },
      "source": [
        "### Print the schema of the prediction dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "id": "6e3ea341",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e3ea341",
        "outputId": "2174e9fa-3118-4c86-da99-fac8042ad7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- class: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- length: integer (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            " |-- token_text: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- stop_tokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- c_vec: vector (nullable = true)\n",
            " |-- tf_idf: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f27055",
      "metadata": {
        "id": "57f27055"
      },
      "source": [
        "## Model Evaluation\n",
        "- Use <b>MulticlassClassificationEvaluator</b> to calculate the <b>f1_score</b>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "id": "61911086",
      "metadata": {
        "id": "61911086"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "id": "be706565",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be706565",
        "outputId": "ee6bfa83-ac44-44e3-e2b0-4e95bf7545f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-Score of the model at predicting spam was: 0.9724817278921944\n"
          ]
        }
      ],
      "source": [
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(predictions)\n",
        "print(\"F1-Score of the model at predicting spam was: {}\".format(acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e00e7b53",
      "metadata": {
        "id": "e00e7b53"
      },
      "source": [
        "# GOOD LUCK\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SaraElaraby_Spark and Python for Big Data Final Exam-Branches.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
